{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RecSysLoLClassifiers.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZujf16p_c2y"
      },
      "source": [
        "# Data Mining for Item Recommendation in MOBA Games\n",
        "Code of section 4.3 Recommender System Based on Classifiers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybR1dWGRAIda"
      },
      "source": [
        "## Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACc79viArHIP"
      },
      "source": [
        "import os\n",
        "import json\n",
        "import pickle\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.externals import joblib\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn import linear_model\n",
        "from sklearn.multiclass import OneVsRestClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGJmV8y0BwdZ"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D81V32smDEc8"
      },
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "# Authenticate and create the PyDrive client.\n",
        "# This only needs to be done once per notebook.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLMFGSqMEtyB"
      },
      "source": [
        "# file ids of datasets\n",
        "file_id = ['1QyC2zho409ctBVSEgylOsqSGdfzPi7On',\n",
        "          '1-4Pqyd1ivq-o33UdzuH4eIgjoq-QdTy5',\n",
        "          '1GBWilejUnIatT7o0QvRUwMefo-ydPAjl',\n",
        "          '1ipgQtMTc_Z-LJuQAtYHTi75jP3UQ1AT5',\n",
        "          '139b8gxLRa02x29p13eNDrGlFC-zMG8hM']"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNkNC0zVD5cL"
      },
      "source": [
        "for id in file_id:\n",
        "  fileId = drive.CreateFile({'id': id})\n",
        "  print(fileId['title'])\n",
        "  fileId.GetContentFile(fileId['title']) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9xIbKHrJmyA"
      },
      "source": [
        "def open_pickle(path):\n",
        "    pickle_in = open(path,\"rb\")\n",
        "    example_dict = pickle.load(pickle_in)\n",
        "    df=example_dict[0]\n",
        "    pickle_in.close()\n",
        "    return df"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oa9L6yMNHZXF"
      },
      "source": [
        "# load training set\n",
        "print('Loading training set..')\n",
        "df = open_pickle('baseline_train_labels_splits.pkl')\n",
        "Y_train = df.values\n",
        "\n",
        "df = open_pickle('baseline_train_inputs_splits.pkl')\n",
        "X_train = df.values\n",
        "\n",
        "# load test set\n",
        "print('Loading test set..')\n",
        "df = open_pickle('baseline_test_labels_splits.pkl')\n",
        "Y_test = df.values\n",
        "item_ids = df.columns.tolist()\n",
        "\n",
        "df = open_pickle('baseline_test_inputs_splits.pkl')\n",
        "X_test = df.values\n",
        "\n",
        "# load items data\n",
        "print('Loading items information..')\n",
        "with open('items.json') as items_json:\n",
        "    data_items = json.load(items_json)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yROjzesAuYw"
      },
      "source": [
        "## Utils"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lk6BclRHIhVo"
      },
      "source": [
        "### Transformations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aaxJrxvVrkiL"
      },
      "source": [
        "id_dictionary = {}\n",
        "for i, j in enumerate(item_ids):\n",
        "    id_dictionary.update({i:j}) # create a indexed dictionary from the items's ids\n",
        "\n",
        "## create function that recieves a one-hot list and returns the respective ids\n",
        "def translate_onehot(onehot, name=True):\n",
        "    ids = [] # create an empty list to collect the ids of the items\n",
        "    names = [] # create an empty list to collect the names of the items\n",
        "    idxs = [i for i, e in enumerate(onehot) if e == 1] # extract indexes of encoded items in the one-hot vector\n",
        "    for idx in idxs: # iterate over the list of indexes\n",
        "        id = id_dictionary[idx] # search the correspondent id according to the index\n",
        "        ids.append(id) # append the id to the list of ids\n",
        "        id_dict = (next(item for item in data_items if item['id'] == str(id))) # search the dictionary that corresponds to the item's id\n",
        "        names.append(id_dict['name']) # extract the name of the item from this dictionary\n",
        "    if name:\n",
        "        return ids, names\n",
        "    else:\n",
        "        return ids\n",
        "\n",
        "## create a function that recieves a output of a classifier and returns a @k itemset\n",
        "def decoding(prediction, itemset_size, id_items):\n",
        "    index_max = np.argsort(prediction)\n",
        "    _set = index_max[(len(id_items)-itemset_size):len(id_items)]\n",
        "    items = np.asarray(id_items)\n",
        "    itemset = items[np.flip(_set)]\n",
        "    return itemset"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I8decmbjIzvs"
      },
      "source": [
        "### Metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MkdwnFbTr0Y"
      },
      "source": [
        "# Forked from https://gist.github.com/bwhite/3726239\n",
        "!wget https://gist.githubusercontent.com/bwhite/3726239/raw/2c92e90259b01b4a657d20c0ad8390caadd59c8b/rank_metrics.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_hSWYr6T3Sr"
      },
      "source": [
        "from rank_metrics import *"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dLu7VLukI8hR"
      },
      "source": [
        "## ANN RecSys Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SYdk2BLeJTN5"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1_eEn8uHHvD"
      },
      "source": [
        "def trainANN(X_train, Y_train, input_size, target_size, save=True):\n",
        "    \"\"\" Function to train a neural net of 2 layer\n",
        " \n",
        "        Parameters\n",
        "        ----------\n",
        "        X_train: inputs\n",
        "        Y_train: targets\n",
        "        input_size: input size of the network\n",
        "        target_size: ouput size of the network\n",
        "        save: if True, save model\n",
        "    \"\"\"\n",
        "    # define modelo y lo entrena\n",
        "    model = Sequential()\n",
        "    model.add(Dense(150, input_dim=input_size, activation='relu'))\n",
        "    model.add(Dense(150, activation='relu'))\n",
        "    model.add(Dense(target_size, activation='sigmoid'))\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    model.fit(X_train, Y_train, epochs=1, batch_size=128, verbose=1, validation_split=0.1, shuffle=True)\n",
        "    if save:\n",
        "        # serializar modelo a JSON\n",
        "        model_json = model.to_json()\n",
        "        with open(\"model.json\", \"w\") as json_file:\n",
        "            json_file.write(model_json)\n",
        "        # serializar pesos a HDF5\n",
        "        model.save_weights(\"model.h5\")\n",
        "        print(\"Model saved\")\n",
        "\n",
        "    return model"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZz4dBsIrz8U"
      },
      "source": [
        "# Train and save the model\n",
        "input_size = 136 # number of champions\n",
        "target_size = 89 # number of items\n",
        "model = trainANN(X_train, Y_train, input_size, target_size, save=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8yKXAKvJxlv"
      },
      "source": [
        "### Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZXHdZlD4MDL"
      },
      "source": [
        "# predictions of test set\n",
        "Y_p = model.predict(X_test)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghKRz6LQ4843"
      },
      "source": [
        "eval_itemset_size = 6 # size of itemset required\n",
        "\n",
        "Relevance=[]\n",
        "Precision = []\n",
        "Recall = []\n",
        "F1 = []\n",
        "\n",
        "for i in tqdm(range(X_test.shape[0]-1)):\n",
        "    targ_items=translate_onehot(Y_test[i], name=False)\n",
        "    # decode output of the model\n",
        "    itemset = decoding(Y_p[i],itemset_size=eval_itemset_size,id_items=item_ids)\n",
        "    rel_items = [int(j in targ_items) for j in itemset]\n",
        "    Relevance.append(rel_items)\n",
        "    num = list(set(itemset) & set(targ_items))\n",
        "    if len(targ_items) >= 1:\n",
        "        precision = (len(num) / len(itemset))\n",
        "        recall = (len(num) / len(targ_items))\n",
        "        Precision.append(precision)\n",
        "        Recall.append(recall)\n",
        "        if precision == 0.0 and recall == 0.0:\n",
        "            F1.append(0)\n",
        "        else:\n",
        "            F1.append(2 * ((precision * recall) / (precision + recall)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWqOUjUM5HFq"
      },
      "source": [
        "_map=mean_average_precision(Relevance)\n",
        "mrr=mean_reciprocal_rank(Relevance)\n",
        "\n",
        "print('MAP:',_map)\n",
        "print('MRR:',mrr)\n",
        "print('Precision:', np.mean(Precision))\n",
        "print('Recall:', np.mean(Recall))\n",
        "print('F1:', np.mean(F1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wu-pzA1xMM5v"
      },
      "source": [
        "## Logit or Decision Tree RecSys Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-9cp5Z44P-q"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6i0xXAV1M6wy"
      },
      "source": [
        "def train(X_tr, Y_tr, model_type, save=True):\n",
        "    if model_type == 'logit':\n",
        "      clf = OneVsRestClassifier(linear_model.SGDClassifier(max_iter=1000, tol=1e-3, loss='log', verbose=True))\n",
        "    elif model_type == 'dtree':\n",
        "      clf = OneVsRestClassifier(DecisionTreeClassifier(random_state=0))\n",
        "    clf.fit(X_tr, Y_tr)\n",
        "    print('Training finished')\n",
        "    if save:\n",
        "        # save model\n",
        "        joblib.dump(clf, 'model.pkl')\n",
        "        print('Model saved')\n",
        "    return clf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttpT5OoTNvNJ"
      },
      "source": [
        "# Train and save the model\n",
        "model_type = 'logit' # choose 'logit' or 'dtree'\n",
        "clf = train(X_train, Y_train, model_type, save=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1ozDlhmNokp"
      },
      "source": [
        "### Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1y-OLhx5Nox6"
      },
      "source": [
        "# predictions of test set\n",
        "Y_p = clf.predict_proba(X_test)\n",
        "pred_classes=clf.classes_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDzz_VfxPd6n"
      },
      "source": [
        "eval_itemset_size = 6 # size of itemset required\n",
        "target_size = 89 # number of items\n",
        "\n",
        "Relevance=[]\n",
        "Precision = []\n",
        "Recall = []\n",
        "F1 = []\n",
        "\n",
        "for i in tqdm(range(X_test.shape[0]-1)):\n",
        "    targ_items=translate_onehot(Y_test[i], name=False)\n",
        "    # adjusting list size\n",
        "    real_pred = []\n",
        "    aux = 0\n",
        "    for j in range(target_size):\n",
        "        if j == pred_classes[aux]:\n",
        "            real_pred.append(Y_p[i][aux])\n",
        "            aux += 1\n",
        "        else:\n",
        "            real_pred.append(0)\n",
        "    # decode output of the model\n",
        "    itemset = decoding(real_pred,itemset_size=eval_itemset_size,id_items=item_ids) #itemset_size = @\n",
        "    rel_items = [int(j in targ_items) for j in itemset]\n",
        "    Relevance.append(rel_items)\n",
        "    num = list(set(itemset) & set(targ_items))\n",
        "    if len(targ_items) >= 1:\n",
        "        precision = (len(num) / len(itemset))\n",
        "        recall = (len(num) / len(targ_items))\n",
        "        Precision.append(precision)\n",
        "        Recall.append(recall)\n",
        "        if precision == 0.0 and recall == 0.0:\n",
        "            F1.append(0)\n",
        "        else:\n",
        "            F1.append(2 * ((precision * recall) / (precision + recall)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Enf2neXR6s4"
      },
      "source": [
        "_map=mean_average_precision(Relevance)\n",
        "mrr=mean_reciprocal_rank(Relevance)\n",
        "\n",
        "print('MAP:',_map)\n",
        "print('MRR:',mrr)\n",
        "print('Precision:', np.mean(Precision))\n",
        "print('Recall:', np.mean(Recall))\n",
        "print('F1:', np.mean(F1))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}